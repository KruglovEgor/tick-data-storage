# Система хранения тиковых данных

Тестовое задание по созданию системы обработки и хранения тиковых данных биржевых заявок с поддержкой PostgreSQL и SQLite.

## Требования

- Python 3.8+
- Docker и Docker Compose (для PostgreSQL)
- pip

## Установка и запуск

### 1. Клонирование репозитория
```bash
git clone https://github.com/KruglovEgor/tick-data-storage.git
cd tick-data-storage
```

### 2. Установка зависимостей
```bash
pip install -r requirements.txt
```

### 3. Запуск PostgreSQL через Docker
```bash
docker-compose up -d
```

### 4. Запуск тестов

#### SQLite версия
```bash
python -m src.main_sqlite
```

#### PostgreSQL версия
```bash
python -m src.main_postgres
```

## Архитектура и индексы

### Почему без индексов?
- Таблица `order_history` используется только для массовой вставки данных (INSERT). Поиск и обновление по полям этой таблицы не выполняется, поэтому любые индексы только замедляют загрузку.
- Таблица `active_orders` содержит только актуальные заявки. Для неё PRIMARY KEY по `order_id` уже создаёт необходимый индекс для быстрых операций поиска, обновления и удаления.
- Дополнительные индексы (по timestamp, составные и т.д.) не используются в логике работы на данный момент. Как именно будут работать с данными нет информации, так что пока ничего не создаем.


## Логика работы скриптов

1. **main_postgres.py / main_sqlite.py** — основные точки входа для работы с PostgreSQL и SQLite.
2. Скрипты создают необходимые таблицы в базе данных.
3. Далее происходит обработка CSV-файла с тиковыми данными:
    - Все события записываются в `order_history` (без индексов).
    - Актуальные заявки поддерживаются в `active_orders` (операции INSERT/UPDATE/DELETE по PRIMARY KEY).
4. После загрузки можно получить аналитику по лучшим ценам и состоянию стакана.


## Архитектура

```
src/
├── db/                    # Слой базы данных
│   ├── __init__.py
│   ├── base.py           # Абстрактный интерфейс
│   ├── postgres.py       # PostgreSQL реализация
│   └── sqlite.py         # SQLite реализация
├── processor.py          # Универсальный процессор
├── queries.py            # SQL запросы
├── main_postgres.py      # Точка входа для PostgreSQL
└── main_sqlite.py        # Точка входа для SQLite
```

## Возможности

- Обработка CSV файлов с тиковыми данными
- Поддержка PostgreSQL и SQLite
- Эффективная обработка больших файлов (порциями)
- Хранение истории всех операций
- Отслеживание активных заявок
- Быстрые запросы для получения лучших цен покупки и продажи

## Типы событий

- `1` - Выставление заявки
- `2` - Сделка (частичное или полное исполнение)
- `0` - Снятие заявки

## Формат данных

CSV файл должен содержать колонки:
- `symbol` - инструмент
- `type` - тип операции (B/S)
- `moment` - временная метка
- `id` - ID заявки
- `action` - тип события (1-выставление, 2-сделка, 0-снятие)
- `price` - цена
- `volume` - объем

## Тестовые данные

В папке `resources/` находятся тестовые файлы:
- `20241001_fut_ord_50k.csv` - файл с первыми 50000 строками для тестирования (сократил для удобства)